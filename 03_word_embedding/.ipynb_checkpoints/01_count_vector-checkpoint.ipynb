{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "720d873b",
   "metadata": {},
   "source": [
    "# Count Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9078a66",
   "metadata": {},
   "source": [
    "## Applying count vector on small text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5e6e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After converting to lower case: \n",
      " doc1: he is a boy. and he is a data scientist \n",
      " doc2: rama is a software employee\n",
      "After Removing stop-words: \n",
      " doc1: boy . data scientist \n",
      " doc2: rama software employee\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Loading the nlp model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.Defaults.stop_words.remove(\"he\")\n",
    "\n",
    "# Input docs\n",
    "doc1 = 'He is a boy. And he is a data scientist'\n",
    "doc2 = 'Rama is a software employee'\n",
    "\n",
    "# Converting to lower case.\n",
    "doc1, doc2 = doc1.lower(), doc2.lower()\n",
    "print(f\"After converting to lower case: \\n doc1: {doc1} \\n doc2: {doc2}\")\n",
    "\n",
    "# Removing stop-words\n",
    "doc1, doc2 = nlp(doc1), nlp(doc2)\n",
    "doc1 = ' '.join([token.text for token in doc1 if not token.is_stop])\n",
    "doc2 = ' '.join([token.text for token in doc2 if not token.is_stop])\n",
    "print(f\"After Removing stop-words: \\n doc1: {doc1} \\n doc2: {doc2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb77de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boy': 0, 'data': 1, 'scientist': 4, 'rama': 3, 'software': 5, 'employee': 2}\n",
      "(1, 6)\n",
      "[[0 1 1 1 1 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# list of text documents\n",
    "text = [doc1, doc2]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "# encode document\n",
    "vector = vectorizer.transform(['rama is a software employee and data scientist'])\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc75501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
