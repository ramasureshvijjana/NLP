# Importing required libreries.
import pandas as pd
import tensorflow as tf
import tensorflow_hub as tf_hub
from sklearn.model_selection import train_test_split
import tensorflow_text as tf_text





data = pd.read_csv("E:/NLP/NLP_Tutorials/02_DATA/spam.csv")
data.head()





data.groupby("Category").describe()


data['Category'].value_counts()


data.isna().sum()











def under_sampling():
    # Selecting spam category data
    spam_data = data[data['Category'] == 'spam']
    ham_data = data[data['Category'] == 'ham']
    print(f'Spam data shape {spam_data.shape} \nHam data shape {ham_data.shape}')
    ham_data = ham_data.sample(747)
    print(f'Ham data shape after under-sample : {ham_data.shape}')
    return pd.concat([spam_data, ham_data])

sampled_data = under_sampling()
print(f"\nThe value counts of is : \n{sampled_data['Category'].value_counts()}\n")
display(sampled_data.head())





# Converting spam as 1 and ham as 0 in "Category" column.
sampled_data['Category'] = sampled_data['Category'].apply(lambda x : 1 if x == 'spam' else 0)
sampled_data['Category'].value_counts() # Checking value counts after enoding.





x_train, x_test, y_train, y_test = train_test_split(sampled_data['Message'], sampled_data['Category'])






preprocessing_layer = tf_hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3")


import sys
print(sys.executable)



